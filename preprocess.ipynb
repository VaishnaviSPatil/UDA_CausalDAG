{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pgmpy\n",
    "from pgmpy.readwrite import BIFReader\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pgmpy\n",
    "from pgmpy.estimators import BDeuScore, K2Score, BicScore\n",
    "from pgmpy.estimators import PC, HillClimbSearch, ExhaustiveSearch\n",
    "from IPython import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset_name, num_samples=10000, ntrails=10):\n",
    "    reader = BIFReader('./data/{}.bif'.format(dataset_name))\n",
    "    bayesmodel = reader.get_model()\n",
    "    with open('./data/{}_model.pkl'.format(dataset_name), 'wb') as f:\n",
    "        pickle.dump(bayesmodel, f)\n",
    "    \n",
    "    samples_dataframe = BayesianModelSampling(bayesmodel).forward_sample(size=num_samples, return_type='dataframe')\n",
    "    x_df = samples_dataframe.drop(['asia', 'xray'], axis=1)\n",
    "    y_df = samples_dataframe.loc[:, samples_dataframe.columns == 'xray']\n",
    "    d_df = samples_dataframe.loc[:, samples_dataframe.columns == 'asia']\n",
    "    network = nx.DiGraph(bayesmodel)\n",
    "    network.remove_node('xray')\n",
    "    network.remove_node('asia')\n",
    "    nodes = list(network.nodes())\n",
    "    edges = list(network.edges())\n",
    "    length = len(nodes)\n",
    "    \n",
    "    layout = nx.spring_layout(network)\n",
    "    with open('./data/{}_layout.pkl'.format(dataset_name), 'wb') as f:\n",
    "        pickle.dump(layout, f)\n",
    "    \n",
    "    nfeatures = np.array([x_df[node].nunique() for node in x_df])\n",
    "    nclass = y_df['xray'].nunique()\n",
    "    ndomain = d_df['asia'].nunique()\n",
    "    np.save('./data/{}_nfeatures.npy'.format(dataset_name), nfeatures)\n",
    "    np.save('./data/{}_nclass.npy'.format(dataset_name), nclass)\n",
    "    np.save('./data/{}_ndomain.npy'.format(dataset_name), ndomain)\n",
    "    \n",
    "    x_enc, y_enc, d_enc = OneHotEncoder(), OneHotEncoder(), OneHotEncoder()\n",
    "    x = x_enc.fit_transform(x_df).toarray()\n",
    "    y = y_enc.fit_transform(y_df).toarray()\n",
    "    d = d_enc.fit_transform(d_df).toarray()\n",
    "    with open('./data/{}_encoders.pkl'.format(dataset_name), 'wb') as f:\n",
    "        pickle.dump((x_enc, y_enc, d_enc), f)    \n",
    "    np.save('./data/{}_x_train.npy'.format(dataset_name), x[:num_samples//5*4,:])\n",
    "    np.save('./data/{}_x_test.npy'.format(dataset_name), x[num_samples//5*4:,:])\n",
    "    np.save('./data/{}_y_train.npy'.format(dataset_name), y[:num_samples//5*4,:])\n",
    "    np.save('./data/{}_y_test.npy'.format(dataset_name), y[num_samples//5*4:,:])\n",
    "    np.save('./data/{}_d_train.npy'.format(dataset_name), d[:num_samples//5*4,:])\n",
    "    np.save('./data/{}_d_test.npy'.format(dataset_name), d[num_samples//5*4:,:])\n",
    "    \n",
    "    node_to_idx = dict(list(zip(nodes, range(length))))\n",
    "    idx_to_node = dict(list(zip(range(length), nodes)))\n",
    "    network = []\n",
    "    for idx in range(length):\n",
    "        local = [idx]\n",
    "        for edge in edges:\n",
    "            if edge[1] == idx_to_node[idx]:\n",
    "                local.append(node_to_idx[edge[0]])\n",
    "        network.append(local)\n",
    "    with open('./data/{}_network.pkl'.format(dataset_name), 'wb') as f:\n",
    "        pickle.dump(network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating for node: xray: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 53.64it/s]\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAMES = ['asia']\n",
    "\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    preprocess(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
