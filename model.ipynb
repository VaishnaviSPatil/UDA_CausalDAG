{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import torch.nn.utils.spectral_norm as sn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mlp model\n",
    "# num_layers will be a number and num_nodes will be a list\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layer, num_nodes, relu_final=False):\n",
    "        super(MLP, self).__init__()\n",
    "        main = nn.Sequential()\n",
    "        for l in np.arange(num_layer - 1):\n",
    "            main.add_module('linear{0}'.format(l), nn.Linear(num_nodes[l], num_nodes[l + 1]))\n",
    "            if relu_final:\n",
    "                main.add_module('relu{0}'.format(l), nn.ReLU())\n",
    "            else:\n",
    "                if num_layer > 2 and l < num_layer - 2: # 2 layers = linear network, >2 layers, relu net\n",
    "                    main.add_module('relu{0}'.format(l), nn.ReLU())\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a MLP generator\n",
    "class MLP_Generator(nn.Module):\n",
    "    def __init__(self, z_dim, pax_dim, plabels_dim, noise_dim, num_layer=1, num_nodes=64):\n",
    "        super(MLP_Generator, self).__init__()\n",
    "\n",
    "        self.decoder = MLP(num_layer + 2, [noise_dim + pax_dim + plabels_dim] + [num_nodes]*num_layer + [z_dim])\n",
    "\n",
    "    # pax is parents of x , plabels are the pseudo labels of the domain\n",
    "    def forward(self, noise, pax, plabels, noise_d=None):\n",
    "\n",
    "        input_gen = torch.cat((pax, noise, plabels), axis=1)\n",
    "        output = self.decoder(input_gen)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator + domain predictor\n",
    "\n",
    "class MLP_AuxClassifier(nn.Module):\n",
    "    def __init__(self, z_dim, plabels_dim, do_num, num_layer=1, num_nodes=64):\n",
    "        super(MLP_AuxClassifier, self).__init__()\n",
    "        # classifying zi's into different domains\n",
    "        self.cls = MLP(num_layer + 2, [z_dim] + [num_nodes]*num_layer +[plabels_dim])\n",
    "        \n",
    "        \n",
    "        self.common_net = MLP(num_layer + 1, [z_dim] + [num_nodes]*num_layer, relu_final=True)\n",
    "        \n",
    "        self.aux_c = nn.Linear(num_nodes, cl_num)\n",
    "        self.aux_c_tw = nn.Linear(num_nodes, cl_num)\n",
    "        \n",
    "        self.aux_d = nn.Linear(num_nodes, do_num)\n",
    "        self.aux_d_tw = nn.Linear(num_nodes, do_num)\n",
    "\n",
    "    def forward(self, input0):\n",
    "        input = self.common_net(input0)\n",
    "        output_c = self.aux_c(input)\n",
    "        output_c_tw = self.aux_c_tw(input)\n",
    "        output_d = self.aux_d(input)\n",
    "        output_d_tw = self.aux_d_tw(input)\n",
    "        output_cls = self.cls(input0)\n",
    "        return output_c, output_c_tw, output_d, output_d_tw, output_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an MLP classifier to predict y\n",
    "class MLP_Classifier(nn.Module):\n",
    "    def __init__(self, i_dim, cl_num, num_layer=1, num_nodes=64):\n",
    "        super(MLP_Classifier, self).__init__()\n",
    "        self.net = MLP(num_layer + 2, [i_dim] + [num_nodes]*num_layer +[cl_num])\n",
    "\n",
    "    def forward(self, input):\n",
    "        output_c = self.net(input)\n",
    "        return output_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph nodes.\n",
    "class Data(object):\n",
    "    def __init__(self, name):\n",
    "        self.__name = name\n",
    "        self.__links = set()\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "\n",
    "    @property\n",
    "    def links(self):\n",
    "        return set(self.__links)\n",
    "\n",
    "    def add_link(self, other):\n",
    "        self.__links.add(other)\n",
    "        other.__links.add(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to represent a graph, for topological sort of DAG\n",
    "class Graph:\n",
    "    def __init__(self, vertices):\n",
    "        self.graph = defaultdict(list)  # dictionary containing adjacency List\n",
    "        self.V = vertices  # No. of vertices\n",
    "\n",
    "    # function to add an edge to graph\n",
    "    def addEdge(self, u, v):\n",
    "        self.graph[u].append(v)\n",
    "\n",
    "    # A recursive function used by topologicalSort\n",
    "    def topologicalSortUtil(self, v, visited, stack):\n",
    "\n",
    "        # Mark the current node as visited.\n",
    "        visited[v] = True\n",
    "\n",
    "        # Recur for all the vertices adjacent to this vertex\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] is False:\n",
    "                self.topologicalSortUtil(i, visited, stack)\n",
    "\n",
    "        # Push current vertex to stack which stores result\n",
    "        stack.insert(0, v)\n",
    "\n",
    "    # The function to do Topological Sort. It uses recursive\n",
    "    # topologicalSortUtil()\n",
    "    def topologicalSort(self):\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * self.V\n",
    "        stack = []\n",
    "\n",
    "        # Call the recursive helper function to store Topological\n",
    "        # Sort starting from all vertices one by one\n",
    "        for i in range(self.V):\n",
    "            if visited[i] is False:\n",
    "                self.topologicalSortUtil(i, visited, stack)\n",
    "\n",
    "        # Return contents of stack\n",
    "        return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a decoder according to a DAG\n",
    "class DAG_Generator(nn.Module):\n",
    "    def __init__(self, num_vertices, plabels_dim, pax_dim, z_dim, num_layer=1, num_nodes=64, dagMat=None):\n",
    "        super(DAG_Generator, self).__init__()\n",
    "        \n",
    "        # create a dag\n",
    "        dag = Graph(num_vertices)\n",
    "\n",
    "        for i in range(num_vertices):\n",
    "            for j in range(num_vertices):\n",
    "                if dagMat[j, i]:\n",
    "                    dag.addEdge(i, j)\n",
    "\n",
    "        # extract y and d signs\n",
    "        \n",
    "        ###########check this#################\n",
    "        self.yd_sign = dagMat[:, -2:]\n",
    "        dagMat = dagMat[:, :-2]\n",
    "\n",
    "        # topological sort\n",
    "        nodeSort = dag.topologicalSort()\n",
    "        numInput = dagMat.sum(1)\n",
    "\n",
    "        self.dnet = nn.Linear(do_num, do_dim * i_dim, bias=False)\n",
    "        \n",
    "        self.cnet = nn.Linear(cl_num, cl_dim * i_dim, bias=False)\n",
    "\n",
    "        # construct generative network according to the dag\n",
    "        nets = nn.ModuleList()\n",
    "        for i in range(i_dim):\n",
    "            num_nodesIn = int(numInput[i]) + cl_dim + do_dim + z_dim\n",
    "            num_nodes_i = [num_nodesIn] + [num_nodes]*num_layer + [1]\n",
    "            netMB = MLP(num_layer + 2, num_nodes_i)\n",
    "            nets.append(netMB)\n",
    "\n",
    "        # prediction network\n",
    "        self.nets = nets\n",
    "        self.nodeSort = nodeSort\n",
    "        self.nodesA = np.array(range(i_dim)).reshape(i_dim, 1).tolist()\n",
    "        self.i_dim = i_dim\n",
    "        self.i_dimNew = i_dim\n",
    "        self.do_num = do_num\n",
    "        self.cl_num = cl_num\n",
    "        self.cl_dim = cl_dim\n",
    "        self.do_dim = do_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.dagMat = dagMat\n",
    "        self.numInput = numInput\n",
    "        self.is_reg = is_reg\n",
    "        self.ischain = False\n",
    "\n",
    "        # inputs: class indicator, domain indicator, noise, features\n",
    "        # separate forward for each factor\n",
    "    def forward_indep(self, noise, input_c, input_d, input_x, noise_d=None, device='cpu'):\n",
    "        # class parameter network\n",
    "        batch_size = input_c.size(0)\n",
    "        if self.is_reg:\n",
    "            inputs_c = input_c.view(batch_size, 1)\n",
    "        else:\n",
    "            inputs_c = self.cnet(input_c)\n",
    "        if self.prob:\n",
    "            theta = self.mu + torch.mul(torch.log(1+torch.exp(self.sigma)), noise_d)\n",
    "            inputs_d = torch.matmul(input_d, theta)\n",
    "        else:\n",
    "            inputs_d = self.dnet(input_d)\n",
    "\n",
    "        inputs_n = noise\n",
    "        inputs_f = input_x\n",
    "\n",
    "        # create output array\n",
    "        output = torch.zeros((batch_size, len(self.nodeSort)))\n",
    "        output = output.to(device)\n",
    "\n",
    "        # create a network for each module\n",
    "        for i in self.nodeSort:\n",
    "            inputs_pDim = self.numInput[i]\n",
    "            if inputs_pDim > 0:\n",
    "                index = np.argwhere(self.dagMat[i, :])\n",
    "                index = index.flatten()\n",
    "                index = [int(j) for j in index]\n",
    "                inputs_p = inputs_f[:, index] # get the parent data from real data, not fake data!!!\n",
    "            if not self.is_reg:\n",
    "                inputs_ci = inputs_c[:, i*self.cl_dim:(i+1)*self.cl_dim]\n",
    "            else:\n",
    "                inputs_ci = inputs_c\n",
    "            inputs_di = inputs_d[:, i*self.do_dim:(i+1)*self.do_dim]\n",
    "            inputs_ni = inputs_n[:, i*self.z_dim:(i+1)*self.z_dim]\n",
    "            if inputs_pDim > 0:\n",
    "                inputs_i = torch.cat((inputs_ci, inputs_di, inputs_ni, inputs_p), 1)\n",
    "            else:\n",
    "                inputs_i = torch.cat((inputs_ci, inputs_di, inputs_ni), 1)\n",
    "\n",
    "            output[:, i] = self.nets[i](inputs_i).squeeze()\n",
    "\n",
    "        if self.prob:\n",
    "            KL_reg = 1 + torch.log(torch.log(1+torch.exp(self.sigma))**2) - self.mu**2 - torch.log(1+torch.exp(self.sigma))**2\n",
    "            if KL_reg.shape[1] > 1:\n",
    "                KL_reg = KL_reg.sum(axis=1)\n",
    "            return output, -KL_reg\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    # inputs: class indicator, domain indicator, noise\n",
    "    # forward for all factors in a graph\n",
    "    def forward(self, noise, input_c, input_d, device='cpu', noise_d=None):\n",
    "        # class parameter network\n",
    "        batch_size = input_c.size(0)\n",
    "        if self.is_reg:\n",
    "            inputs_c = input_c.view(batch_size, 1)\n",
    "        else:\n",
    "            inputs_c = self.cnet(input_c)\n",
    "        if self.prob:\n",
    "            theta = self.mu + torch.mul(torch.log(1+torch.exp(self.sigma)), noise_d)\n",
    "            inputs_d = torch.matmul(input_d, theta)\n",
    "        else:\n",
    "            inputs_d = self.dnet(input_d)\n",
    "\n",
    "        inputs_n = noise\n",
    "\n",
    "        output = torch.zeros((batch_size, len(self.nodeSort)))\n",
    "        output = output.to(device)\n",
    "\n",
    "        # create a network for each module\n",
    "        for i in self.nodeSort:\n",
    "            inputs_pDim = self.numInput[i]\n",
    "            if inputs_pDim > 0:\n",
    "                index = np.argwhere(self.dagMat[i, :])\n",
    "                index = index.flatten()\n",
    "                index = [int(j) for j in index]\n",
    "                inputs_p = output[:, index]\n",
    "\n",
    "            if not self.is_reg:\n",
    "                inputs_ci = inputs_c[:, i * self.cl_dim:(i + 1) * self.cl_dim]\n",
    "            else:\n",
    "                inputs_ci = inputs_c\n",
    "            inputs_di = inputs_d[:, i * self.do_dim:(i + 1) * self.do_dim]\n",
    "            inputs_ni = inputs_n[:, i * self.z_dim:(i + 1) * self.z_dim]\n",
    "            if inputs_pDim > 0:\n",
    "                inputs_i = torch.cat((inputs_ci, inputs_di, inputs_ni, inputs_p), 1)\n",
    "            else:\n",
    "                inputs_i = torch.cat((inputs_ci, inputs_di, inputs_ni), 1)\n",
    "\n",
    "            output[:, i] = self.nets[i](inputs_i).squeeze()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
